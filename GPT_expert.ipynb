{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a250f32a-1b62-46c9-8905-dff5f11d3ff5",
   "metadata": {},
   "source": [
    "##### GPT-4o \"as an expert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e7f01e-35a2-4f5d-aade-6173ae549143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, pickle, os, json, random\n",
    "from tqdm import tqdm\n",
    "from figurative_flute.utils import postprocess_output_few\n",
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = 'MY_OPENAI_API_KEY'\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "src_path = './outputs/finetuning/gemma2_5e-5/outputs/test/pred_ref_test.csv'\n",
    "\n",
    "df_flute = pd.read_csv('./figurative_flute/data/outputs/flute/outputs.csv')\n",
    "df_gemma2 = pd.read_csv(src_path)\n",
    "gemma2_labels, gemma2_explanations = df_gemma2['pred_label'], df_gemma2['pred_explanation'].fillna('').to_list()\n",
    "premises, hypothesis, ref_labels, ref_explanations = df_flute['premise'].to_list(), df_flute['hypothesis'].to_list(), df_flute['ref_label'].to_list(), df_flute['ref_explanation'].to_list()\n",
    "assert len(gemma2_labels) == len(gemma2_explanations) == len(ref_labels) == len(ref_explanations) == len(premises) == len(hypothesis)\n",
    "\n",
    "def extract_expl_examples(k):\n",
    "    raw_data = json.load(open('./figurative_flute/data/train.json', 'r'))\n",
    "    expl = [d['explanation'] for d in raw_data if len(d['explanation']) > 5]\n",
    "    random.seed(42)\n",
    "    indices = random.sample(range(len(expl)), k)\n",
    "    return [expl[i] for i in indices]\n",
    "\n",
    "def process_output_expert(output):\n",
    "    if 'Label:' in output:\n",
    "        label = output.split('Label:')[1].split('\\n')[0].strip()\n",
    "    else:\n",
    "        label = output.split('\\n')[0].strip()\n",
    "    label = 'Entailment' if 'entail' in label.lower() else 'Contradiction' if 'contradict' in label.lower() else 'Correct'\n",
    "    if 'Explanation:' in output:\n",
    "        explanation = output.split('Explanation:')[1].split('\\n')[0].strip()\n",
    "    else:\n",
    "        explanation = output[output.rfind(':')+1:].strip()\n",
    "    return label, explanation\n",
    "\n",
    "template1 = \"\"\"I will provide you with a pair of sentences consisting of a premise and a hypothesis containing figurative language. The task is to determine whether there is a contradiction or entailment between the premise and hypothesis, and provide an explanation for it.\n",
    "I will also provide you with a model's prediction (\"Entailment\" or \"Contradiction\") and explanation.\n",
    "Your task is to verify the correctness of the prediction and, if needed, improve the explanation. When modifying the explanation, do not explicitly mention \"premise\" or \"hypothesis\", and keep the same length and style of the model's generated one.\n",
    "\n",
    "Premise: [PREMISE]\n",
    "Hypothesis: [HYPOTHESIS]\n",
    "\n",
    "Model's prediction\n",
    "Label: [PRED_LABEL]\n",
    "Explanation: [PRED_EXPL]\n",
    "\n",
    "Answer with\n",
    "Label:\n",
    "Explanation:\n",
    "If the label is the same as the model's prediction, write \"Correct\". If the explanation does not need improvement, write \"Correct\".\"\"\"\n",
    "\n",
    "templates = {1: template1}\n",
    "expl_few_shot = 10\n",
    "\n",
    "template_id = 1\n",
    "\n",
    "out_folder = f'./outputs/gpt_expert/template_{template_id}' + (f'_k{expl_few_shot}/' if expl_few_shot > 0 else '/')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "with open(f'{out_folder}args.txt', 'w') as f:\n",
    "    f.write(f'src_path={src_path}\\ntemplate_id={template_id}')\n",
    "if os.path.exists(f'{out_folder}errors.txt'): os.remove(f'{out_folder}errors.txt')\n",
    "\n",
    "full_outputs, expert_labels, expert_explanations = [], [], []\n",
    "\n",
    "for p, h, pred_label, pred_expl in tqdm(zip(premises, hypothesis, gemma2_labels, gemma2_explanations), total=len(gemma2_explanations)):\n",
    "    prompt = templates[template_id].replace('[PREMISE]', p).replace('[HYPOTHESIS]', h).replace('[PRED_LABEL]', pred_label).replace('[PRED_EXPL]', pred_expl)\n",
    "    if expl_few_shot > 0:\n",
    "        expl_examples = [f'- {e}' for e in extract_expl_examples(expl_few_shot)]\n",
    "        few_shot = f'In the following you can find some examples of explanations. Use the same style.\\n' + '\\n'.join(expl_examples)\n",
    "        ix = prompt.find('Premise')\n",
    "        prompt = prompt[:ix] + few_shot + '\\n\\n' + prompt[ix:]\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try:\n",
    "        completion = client.chat.completions.create(model='gpt-4o-2024-05-13', messages=messages, temperature=0.0, max_tokens=64, seed=42)\n",
    "        output_text = completion.choices[0].message.content\n",
    "        expert_label, expert_explanation = process_output_expert(output_text)\n",
    "        if expert_label.lower() in pred_label.lower(): expert_label = 'Correct'\n",
    "    except:\n",
    "        expert_label, expert_explanation = '', ''\n",
    "        if not 'output_text' in locals(): output_text = 'API Error'\n",
    "        with open(f'{out_folder}errors.txt', 'a') as f:\n",
    "            f.write(f'### Prompt ###\\n{prompt}\\n### Output ###\\n{output_text}\\n### Pred label ###\\n{expert_label}\\n### Pred explanation ###\\n{expert_explanation}\\n@@@@@@@@@@@@@@@@@@@@@@\\n')\n",
    "    full_outputs.append(output_text)\n",
    "    expert_labels.append(expert_label)\n",
    "    expert_explanations.append(expert_explanation)\n",
    "    \n",
    "for i, (g_lab, g_exp, e_lab, e_exp) in enumerate(zip(gemma2_labels, gemma2_explanations, expert_labels, expert_explanations)):\n",
    "    if e_lab == '': expert_labels[i] = g_lab\n",
    "    if e_exp == '': expert_explanations[i] = g_exp\n",
    "    \n",
    "df_pred_ref = pd.DataFrame({'original_label': gemma2_labels, 'pred_label': expert_labels, 'ref_label': ref_labels, 'original_explanation': gemma2_explanations, 'pred_explanation': expert_explanations, 'ref_explanation': ref_explanations, 'output': full_outputs})\n",
    "df_pred_ref.to_csv(f'{out_folder}expert_pred_ref.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f7e53-8221-49d7-a989-a36280d00b8e",
   "metadata": {},
   "source": [
    "###### process and analyze output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2cc94-7652-4ed9-afe7-f8bd82d6273b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, pickle, os\n",
    "\n",
    "template_id = 1\n",
    "df_expert = pd.read_csv(f'./outputs/gpt_expert/template_{template_id}_k10/expert_pred_ref.csv')\n",
    "df_gemma2 = pd.read_csv('./outputs/finetuning/gemma2_5e-5/outputs/test/pred_ref_test.csv')\n",
    "\n",
    "expert_labels, expert_explanations = df_expert['pred_label'].to_list(), df_expert['pred_explanation'].fillna('').to_list()\n",
    "gemma2_labels, gemma2_explanations = df_gemma2['pred_label'].to_list(), df_gemma2['pred_explanation'].fillna('').to_list()\n",
    "ref_labels, ref_explanations = df_gemma2['ref_label'].to_list(), df_gemma2['ref_explanation'].to_list()\n",
    "assert len(expert_labels) == len(gemma2_labels) == len(expert_explanations) == len(gemma2_explanations) == len(ref_labels) == len(ref_explanations)\n",
    "\n",
    "gemma2_expert_labels, gemma2_expert_explanations = [], []\n",
    "\n",
    "for g_lab, g_exp, e_lab, e_exp in zip(gemma2_labels, gemma2_explanations, expert_labels, expert_explanations):\n",
    "    # label\n",
    "    if 'correct' in e_lab.lower() or g_lab == e_lab:\n",
    "        gemma2_expert_labels.append(g_lab)\n",
    "        gemma2_expert_explanations.append(g_exp)\n",
    "    else:\n",
    "        gemma2_expert_labels.append(e_lab)\n",
    "        # explanation\n",
    "        if e_exp.lower().startswith('correct'):\n",
    "            gemma2_expert_explanations.append(g_exp)\n",
    "        else:\n",
    "            gemma2_expert_explanations.append(e_exp)\n",
    "assert len(gemma2_expert_labels) == len(gemma2_expert_explanations) == len(ref_explanations)\n",
    "\n",
    "out_folder = f'./outputs/gpt_expert/template_{template_id}_k10/'\n",
    "df_pred_ref = pd.DataFrame({'pred_label': gemma2_expert_labels, 'ref_label': ref_labels, 'pred_explanation': gemma2_expert_explanations, 'ref_explanation': ref_explanations})\n",
    "# df_pred_ref.to_csv(f'{out_folder}gemma2_expert_pred_ref_v2.csv', sep=',', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

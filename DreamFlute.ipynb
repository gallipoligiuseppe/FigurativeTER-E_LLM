{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970525bb-d7cd-46da-a1ef-18f79878fcbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reproduce results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda3a05-22b6-497b-aaae-f9d8c9162195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch, json, pandas as pd, numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "test_data = json.load(open('./figurative_flute/data/test.json', 'r'))\n",
    "\n",
    "# print(premise)\n",
    "# print(hypothesis)\n",
    "# print(fig)\n",
    "# print(f'{label} | {pred_label}')\n",
    "# print(f'{expl} | {pred_expl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8094991-1445-4cb7-8337-c1901294d3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1663cbc4-2a54-47dd-81c3-a4fe2584757d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### System 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a369e9e-f84f-430f-9dd7-adbc0cef9c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System1_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    input_string = f\"Premise: {premise} Hypothesis: {hypothesis} \" \n",
    "    input_string += \"Is there a contradiction or entailment between the premise and hypothesis?\"\n",
    "    # print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    pred_label = output.split('.')[0].split(':')[1].strip()\n",
    "    pred_expl = output.split('.')[1].split(':')[1].strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cb7d7b-1cd7-420f-874e-79f42696f496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys1_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2c864c-8b74-41f6-8bbc-0497125fda13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### System 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d899f-d223-4b99-bef2-35af83f6c170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System2_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    input_string = f\"Premise: {premise} Hypothesis: {hypothesis} \" \n",
    "    input_string += \"What is the type of figurative language involved? Is there a contradiction or entailment between the premise and hypothesis?\"\n",
    "    #print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    pred_label = output.split('.')[0].split(']')[2].strip()\n",
    "    pred_expl = output.split('.')[1].split(':')[1].strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217664ed-56af-401b-9068-db5c3fe23ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys2_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259f110-dc9e-4c92-a957-cc21a57f9f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed716f1f-6e3e-4b42-8c0b-f4046489e416",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### System 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccea109-d60e-46cb-a6ff-c7274eab89b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_dream_scene(premise, hypothesis, scene_type, dream_data):\n",
    "    for dream_sample in dream_data:\n",
    "        if dream_sample['premise'] == premise and dream_sample['hypothesis'] == hypothesis:\n",
    "            return dream_sample[f'premise_{scene_type}'], dream_sample[f'hypothesis_{scene_type}']\n",
    "    return '', ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590df61d-b22a-4cbb-b4b8-c6a76e6fa3a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf92da5-a70a-4747-9241-19259e17d6bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dream_data = json.load(open('./figurative_flute/data/dream/test_dream.json', 'r'))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System3_DREAM_FLUTE_emotion_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    premise_dream, hypothesis_dream = find_dream_scene(premise, hypothesis, 'emotion', test_dream_data)\n",
    "    input_string = f\"Premise: {premise} [Premise - emotion] {premise_dream} Hypothesis: {hypothesis} [Hypothesis - emotion] {hypothesis_dream} \"\n",
    "    input_string += \"Is there a contradiction or entailment between the premise and hypothesis?\"\n",
    "    # print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    pred_label = output.split('.')[0].split(':')[1].strip()\n",
    "    pred_expl = output.split('.')[1].split(':')[1].strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68733817-0601-4267-98c0-31b9b9d616bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys3_emotion_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141fcac-74fa-4015-91ab-c48614d0e623",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14560863-3e8d-4e83-b338-16b17750a483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dream_data = json.load(open('./figurative_flute/data/dream/test_dream.json', 'r'))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System3_DREAM_FLUTE_motivation_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    premise_dream, hypothesis_dream = find_dream_scene(premise, hypothesis, 'motivation', test_dream_data)\n",
    "    input_string = f\"Premise: {premise} [Premise - motivation] {premise_dream} Hypothesis: {hypothesis} [Hypothesis - motivation] {hypothesis_dream} \"\n",
    "    input_string += \"Is there a contradiction or entailment between the premise and hypothesis?\"\n",
    "    # print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    # print(output)\n",
    "    pred_label = output.split('.')[0].split(':')[1].strip()\n",
    "    pred_expl = output.split('.')[1].split(':')[1].strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc6890-f3ab-4fe2-98c7-0ffcfa539def",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys3_motivation_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5da7d-1ce5-417d-9af8-d8acb0500a0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### consequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776c4e1-f1cc-4b8a-bbc6-9e941615362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dream_data = json.load(open('./figurative_flute/data/dream/test_dream.json', 'r'))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System3_DREAM_FLUTE_consequence_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    premise_dream, hypothesis_dream = find_dream_scene(premise, hypothesis, 'consequence', test_dream_data)\n",
    "    input_string = f\"Premise: {premise} [Premise - likely consequence] {premise_dream} Hypothesis: {hypothesis} [Hypothesis - likely consequence] {hypothesis_dream} \"\n",
    "    input_string += \"Is there a contradiction or entailment between the premise and hypothesis?\"\n",
    "    # print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    # print(output)\n",
    "    pred_label = output.split('.')[0].split(':')[1].strip()\n",
    "    pred_expl = output.split('.')[1].split(':')[1].strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99248ea-3d69-4661-9bc3-be37dc59e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys3_consequence_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef1bf4d-f200-4576-8850-4b7172c98ee3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### social norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e529e90b-9795-4d29-bd11-88f57d9b7fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dream_data = json.load(open('./figurative_flute/data/dream/test_dream.json', 'r'))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System3_DREAM_FLUTE_social_norm_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    premise_dream, hypothesis_dream = find_dream_scene(premise, hypothesis, 'rot', test_dream_data)\n",
    "    input_string = f\"Premise: {premise} [Premise - social norm] {premise_dream} Hypothesis: {hypothesis} [Hypothesis - social norm] {hypothesis_dream} \"\n",
    "    input_string += \"Is there a contradiction or entailment between the premise and hypothesis?\"\n",
    "    # print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    # print(output)\n",
    "    pred_label = output.split('.')[0].split(':')[1].strip()\n",
    "    pred_expl = output.split('.')[1].split(':')[1].strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99acf2e1-2ef0-451f-a182-9e5d76717e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys3_rot_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5769d751-d57c-4021-ad7d-590a212e3010",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### all 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0e7d4-7760-45ed-940b-a07a63707d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dream_data = json.load(open('./figurative_flute/data/dream/test_dream.json', 'r'))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System3_DREAM_FLUTE_all_dimensions_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    premise_dream_emotion, hypothesis_dream_emotion = find_dream_scene(premise, hypothesis, 'emotion', test_dream_data)\n",
    "    premise_dream_motivation, hypothesis_dream_motivation = find_dream_scene(premise, hypothesis, 'motivation', test_dream_data)\n",
    "    premise_dream_consequence, hypothesis_dream_consequence = find_dream_scene(premise, hypothesis, 'consequence', test_dream_data)\n",
    "    premise_dream_social, hypothesis_dream_social = find_dream_scene(premise, hypothesis, 'rot', test_dream_data)\n",
    "    input_string = f\"Premise: {premise} [Premise - social norm] {premise_dream_social} [Premise - emotion] {premise_dream_emotion} [Premise - motivation] {premise_dream_motivation} [Premise - likely consequence] {premise_dream_consequence} \"\n",
    "    input_string += f\"Hypothesis: {hypothesis} [Hypothesis - social norm] {hypothesis_dream_social} [Hypothesis - emotion] {hypothesis_dream_emotion} [Hypothesis - motivation] {hypothesis_dream_motivation} [Hypothesis - likely consequence] {hypothesis_dream_consequence} \"\n",
    "    input_string += \"Is there a contradiction or entailment between the premise and hypothesis?\"\n",
    "    # print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    # print(output)\n",
    "    pred_label = output.split('.')[0].split(':')[1].strip()\n",
    "    pred_expl = output.split('.')[1].split(':')[1].strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2017a9a-00e3-4e37-9695-04b1720e4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys3_4dim_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1932618-2c71-41ee-ae36-91ecc913e93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "218b8bc6-2d36-4701-b134-1d0b2158425d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### System 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ea26b-e213-4411-855f-4a96f4ae9593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-3b\")\n",
    "model_clf = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System4_classify_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "model_exp = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/System4_explain_FigLang2022\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "prems, hypos, fig_types, tgt_labels, tgt_explanations, pred_labels, pred_explanations = [], [], [], [], [], [], []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypothesis, fig = sample['premise'], sample['hypothesis'], sample['fig_type']\n",
    "    label, expl = sample['label'], sample['explanation']\n",
    "    input_string = f\"Premise: {premise} Hypothesis: {hypothesis} \" \n",
    "    input_string += \"Is there a contradiction or entailment between the premise and hypothesis? Answer : \"\n",
    "    #print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model_clf.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    pred_label = output.strip()\n",
    "    input_string = f\"Premise: {premise} Hypothesis: {hypothesis} \" \n",
    "    input_string += f\"Is there a contradiction or entailment between the premise and hypothesis? Answer : {pred_label}. Explanation : \"\n",
    "    #print(input_string)\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "    output = model_exp.generate(input_ids, max_length=200)\n",
    "    output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    pred_expl = output.strip()\n",
    "    prems.append(premise)\n",
    "    hypos.append(hypothesis)\n",
    "    fig_types.append(fig)\n",
    "    tgt_labels.append(label)\n",
    "    tgt_explanations.append(expl)\n",
    "    pred_labels.append(pred_label)\n",
    "    pred_explanations.append(pred_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979de00-4e54-4835-a354-112a27b121dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(prems) == len(hypos) == len(fig_types) == len(pred_labels) == len(tgt_labels) == len(pred_explanations) == len(tgt_explanations)\n",
    "print(len(prems))\n",
    "\n",
    "cols = ['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation']\n",
    "df = pd.DataFrame(list(zip(prems, hypos, fig_types, pred_labels, tgt_labels, pred_explanations, tgt_explanations)), columns=cols)\n",
    "\n",
    "path = './figurative_flute/data/outputs/dream/'\n",
    "df.to_csv(f'{path}sys4_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388e451-da0f-4287-9f73-975847f61457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afec044b",
   "metadata": {},
   "source": [
    "#### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c49386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "acc0_systems = [('sys1', 0.9465954606141522),('sys2', 0.9485981308411215),('sys3_emotion', 0.9392523364485982),('sys3_motivation', 0.9485981308411215),('sys3_consequence', 0.9459279038718291),('sys3_rot', 0.9238985313751669),('sys3_4dim', 0.9492656875834445),('sys4', 0.951935914552737)]\n",
    "top5_acc0_systems = sorted(acc0_systems, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "dream_flute_outputs_path = './figurative_flute/data/outputs/dream/'\n",
    "outputs_files = list(filter(lambda f: f.endswith('.csv'), os.listdir(dream_flute_outputs_path)))\n",
    "\n",
    "df_tmp = pd.read_csv(dream_flute_outputs_path + outputs_files[0])\n",
    "premises, hypotheses, fig_types, labels, explanations = df_tmp['premise'].tolist(), df_tmp['hypothesis'].tolist(), df_tmp['type'].tolist(), df_tmp['ref_label'].tolist(), df_tmp['ref_explanation'].tolist()\n",
    "\n",
    "df_labels = pd.DataFrame()\n",
    "\n",
    "for system, _ in top5_acc0_systems:\n",
    "    for file in outputs_files:\n",
    "        if system in file:\n",
    "            sys_labels = pd.read_csv(dream_flute_outputs_path + file)['pred_label'].tolist()\n",
    "            df_labels[system] = sys_labels\n",
    "\n",
    "# majority voting\n",
    "df_labels['ensemble_label'] = df_labels.mode(axis=1)[0]\n",
    "ensemble_labels = df_labels['ensemble_label'].tolist()\n",
    "\n",
    "ordered_systems = ['sys3_consequence', 'sys3_emotion', 'sys2', 'sys3_4dim', 'sys3_motivation', 'sys4', 'sys1']\n",
    "ordered_systems_files = [f for system in ordered_systems for f in outputs_files if system in f]\n",
    "ensemble_explanations = []\n",
    "\n",
    "for sample_ix in range(len(df_tmp)):\n",
    "    for system_file in ordered_systems_files:\n",
    "        sys_lab, sys_expl = pd.read_csv(dream_flute_outputs_path + system_file).iloc[sample_ix][['pred_label', 'pred_explanation']]\n",
    "        if sys_lab == ensemble_labels[sample_ix]:\n",
    "            ensemble_explanations.append(sys_expl)\n",
    "            break\n",
    "\n",
    "df_out = pd.DataFrame(list(zip(premises, hypotheses, fig_types, ensemble_labels, labels, ensemble_explanations, explanations)), columns=['premise', 'hypothesis', 'type', 'pred_label', 'ref_label', 'pred_explanation', 'ref_explanation'])\n",
    "df_out.to_csv(dream_flute_outputs_path + 'sys5_ensemble_outputs.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793c261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7919a910-1962-48c6-a5ec-8e36a8476758",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### DREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686351b0-5494-460f-8455-45ed1f23d152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch, json\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/DREAM\", torch_dtype=torch.float16, device_map=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-11b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cd864-d55e-49c0-879c-06979494cf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = json.load(open('./figurative_flute/data/train.json', 'r'))\n",
    "train_data_dream = []\n",
    "\n",
    "for sample in tqdm(train_data):\n",
    "    premise, hypo = sample['premise'], sample['hypothesis']\n",
    "    sample_dream = {**sample}\n",
    "    for sent_type in ['premise', 'hypothesis']:\n",
    "        for dream_type in ['motivation', 'emotion', 'rot', 'consequence']:\n",
    "            input_string = f\"$answer$ ; $question$ = [SITUATION] {premise if sent_type == 'premise' else hypo} [QUERY] {dream_type}\"\n",
    "            # print(input_string)\n",
    "            input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "            output = model.generate(input_ids, max_length=200)\n",
    "            output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "            if dream_type != 'consequence':\n",
    "                dream_out = output.split('$ =')[1].strip()\n",
    "            else:\n",
    "                if 'consequence]' in output:\n",
    "                    dream_out = output.split('consequence]')[1].strip()\n",
    "                else:\n",
    "                    dream_out = output.split('$ =')[1].strip()\n",
    "            sample_dream[f'{sent_type}_{dream_type}'] = dream_out\n",
    "            # print(dream_out)\n",
    "    train_data_dream.append(sample_dream)\n",
    "    if len(train_data_dream) % 500 == 0:\n",
    "        with open(f'./figurative_flute/data/train_dream_{len(train_data_dream)}.json', \"w\") as json_file:\n",
    "            json.dump(train_data_dream, json_file, indent=4)\n",
    "assert len(train_data) == len(train_data_dream)\n",
    "    \n",
    "with open('./figurative_flute/data/train_dream.json', \"w\") as json_file:\n",
    "    json.dump(train_data_dream, json_file, indent=4)\n",
    "    \n",
    "###############\n",
    "\n",
    "val_data = json.load(open('./figurative_flute/data/val.json', 'r'))\n",
    "val_data_dream = []\n",
    "\n",
    "for sample in tqdm(val_data):\n",
    "    premise, hypo = sample['premise'], sample['hypothesis']\n",
    "    sample_dream = {**sample}\n",
    "    for sent_type in ['premise', 'hypothesis']:\n",
    "        for dream_type in ['motivation', 'emotion', 'rot', 'consequence']:\n",
    "            input_string = f\"$answer$ ; $question$ = [SITUATION] {premise if sent_type == 'premise' else hypo} [QUERY] {dream_type}\"\n",
    "            # print(input_string)\n",
    "            input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "            output = model.generate(input_ids, max_length=200)\n",
    "            output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "            if dream_type != 'consequence':\n",
    "                dream_out = output.split('$ =')[1].strip()\n",
    "            else:\n",
    "                if 'consequence]' in output:\n",
    "                    dream_out = output.split('consequence]')[1].strip()\n",
    "                else:\n",
    "                    dream_out = output.split('$ =')[1].strip()\n",
    "            sample_dream[f'{sent_type}_{dream_type}'] = dream_out\n",
    "            # print(dream_out)\n",
    "    val_data_dream.append(sample_dream)\n",
    "    if len(val_data_dream) % 250 == 0:\n",
    "        with open(f'./figurative_flute/data/val_dream_{len(val_data_dream)}.json', \"w\") as json_file:\n",
    "            json.dump(val_data_dream, json_file, indent=4)\n",
    "assert len(val_data) == len(val_data_dream)\n",
    "    \n",
    "with open('./figurative_flute/data/val_dream.json', \"w\") as json_file:\n",
    "    json.dump(val_data_dream, json_file, indent=4)\n",
    "    \n",
    "###############\n",
    "\n",
    "test_data = json.load(open('./figurative_flute/data/test.json', 'r'))\n",
    "test_data_dream = []\n",
    "\n",
    "for sample in tqdm(test_data):\n",
    "    premise, hypo = sample['premise'], sample['hypothesis']\n",
    "    sample_dream = {**sample}\n",
    "    for sent_type in ['premise', 'hypothesis']:\n",
    "        for dream_type in ['motivation', 'emotion', 'rot', 'consequence']:\n",
    "            input_string = f\"$answer$ ; $question$ = [SITUATION] {premise if sent_type == 'premise' else hypo} [QUERY] {dream_type}\"\n",
    "            # print(input_string)\n",
    "            input_ids = tokenizer.encode(input_string, return_tensors=\"pt\").to(device)\n",
    "            output = model.generate(input_ids, max_length=200)\n",
    "            output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "            if dream_type != 'consequence':\n",
    "                dream_out = output.split('$ =')[1].strip()\n",
    "            else:\n",
    "                if 'consequence]' in output:\n",
    "                    dream_out = output.split('consequence]')[1].strip()\n",
    "                else:\n",
    "                    dream_out = output.split('$ =')[1].strip()\n",
    "            sample_dream[f'{sent_type}_{dream_type}'] = dream_out\n",
    "            # print(dream_out)\n",
    "    test_data_dream.append(sample_dream)\n",
    "    if len(test_data_dream) % 250 == 0:\n",
    "        with open(f'./figurative_flute/data/test_dream_{len(test_data_dream)}.json', \"w\") as json_file:\n",
    "            json.dump(test_data_dream, json_file, indent=4)\n",
    "assert len(test_data) == len(test_data_dream)\n",
    "    \n",
    "with open('./figurative_flute/data/test_dream.json', \"w\") as json_file:\n",
    "    json.dump(test_data_dream, json_file, indent=4)\n",
    "    \n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2123bc-6574-4af0-bc97-5d09c684ce4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "figurative",
   "language": "python",
   "name": "figurative"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
